{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:45:33.745551Z",
     "start_time": "2020-05-31T15:44:42.375452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.set(font_scale=1)\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from sklearn.metrics import  f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:45:38.754329Z",
     "start_time": "2020-05-31T15:45:33.746418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(10,5))\\nax = sns.countplot(\\'tag\\', data=df.loc[df[\\'tag\\'] != \\'O\\'])\\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\\nplt.tight_layout()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "data.dropna(inplace=True)\n",
    "df=pd.DataFrame({'word':data.word,'tag':data.tag,'pos':data.pos})\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = sns.countplot('tag', data=df.loc[df['tag'] != 'O'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "plt.tight_layout()\n",
    "'''\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:46:25.684245Z",
     "start_time": "2020-05-31T15:45:38.755325Z"
    }
   },
   "outputs": [],
   "source": [
    "converted_data = []\n",
    "\n",
    "i = 0\n",
    "cnt = 0\n",
    "while i < len(df):\n",
    "    ls = []\n",
    "    while (i + 1 < len(df)) & (df.word[i] != '.'):\n",
    "        ls.append(df.word[i]) \n",
    "        i += 1\n",
    "    i += 1\n",
    "    converted_data.append(ls)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:51:54.408371Z",
     "start_time": "2020-05-31T15:51:54.402387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=0\n",
    "for sent in converted_data[:1000]:\n",
    "    if len(sent)>max_len:\n",
    "        max_len=len(sent)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:50:11.466795Z",
     "start_time": "2020-05-31T15:50:11.461808Z"
    }
   },
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.prev=0\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch%10==9:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch+1, loss-self.prev))\n",
    "        self.prev=loss\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:21:07.235438Z",
     "start_time": "2020-05-31T16:20:29.175310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 10: 394708.5\n",
      "Loss after epoch 20: 348754.5\n",
      "Loss after epoch 30: 336043.0\n",
      "Loss after epoch 40: 321351.0\n",
      "Loss after epoch 50: 285576.0\n",
      "Loss after epoch 60: 294918.0\n",
      "Loss after epoch 70: 294024.0\n",
      "Loss after epoch 80: 279892.0\n",
      "Loss after epoch 90: 278656.0\n",
      "Loss after epoch 100: 277294.0\n"
     ]
    }
   ],
   "source": [
    "size = 5\n",
    "model_w = Word2Vec(converted_data,\n",
    "                 size=size,\n",
    "                 window=5,\n",
    "                 min_count=1,\n",
    "                 sample=0.001,\n",
    "                 seed=1,\n",
    "                 workers=4,\n",
    "                 sg=0,\n",
    "                 negative=5,\n",
    "                 iter=100,\n",
    "                 compute_loss=True,\n",
    "                 callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:21:12.961420Z",
     "start_time": "2020-05-31T16:21:07.237432Z"
    }
   },
   "outputs": [],
   "source": [
    "t=0\n",
    "corpus = []\n",
    "for sent in converted_data:\n",
    "    temp=[]\n",
    "    for word in sent:\n",
    "        t+=1\n",
    "        #scaling = MinMaxScaler(feature_range=(-1, 1)).fit(model[word].reshape(-1, 1))\n",
    "        wrd = model_w[word]\n",
    "        temp.append(wrd)\n",
    "    corpus.append(np.array(temp))\n",
    "corpus=np.array(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:21:13.214739Z",
     "start_time": "2020-05-31T16:21:12.962386Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_new=np.squeeze(tf.keras.preprocessing.sequence.pad_sequences(corpus, maxlen=96, padding='post')).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:21:43.884475Z",
     "start_time": "2020-05-31T16:21:43.879490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47896, 96, 5)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:52:24.215890Z",
     "start_time": "2020-05-31T15:52:24.141076Z"
    }
   },
   "outputs": [],
   "source": [
    "unq_labels=list(set(df.tag))\n",
    "unq_labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T15:52:25.528998Z",
     "start_time": "2020-05-31T15:52:25.525008Z"
    }
   },
   "outputs": [],
   "source": [
    "dct={}\n",
    "for idx,x in enumerate(unq_labels):\n",
    "    dct[x]=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:19:54.556113Z",
     "start_time": "2020-05-31T16:19:02.596788Z"
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "prep_label=[]\n",
    "while i < len(df):\n",
    "    ls = []\n",
    "    while (i + 1 < len(df)) & (df.word[i] != '.'):\n",
    "        if df.tag[i] in unq_labels:\n",
    "            \n",
    "            ls.append(dct[df.tag[i]]) \n",
    "        else:\n",
    "            ls.append(0)\n",
    "        i += 1\n",
    "    i += 1\n",
    "    prep_label.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:19:54.761514Z",
     "start_time": "2020-05-31T16:19:54.557060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47896, 96)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_label_new=np.squeeze(tf.keras.preprocessing.sequence.pad_sequences(prep_label, maxlen=96, padding='post',value=0))\n",
    "prep_label_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:24:50.099357Z",
     "start_time": "2020-05-31T16:24:50.095366Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "rnn_units=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:24:50.608311Z",
     "start_time": "2020-05-31T16:24:50.601296Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model( rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                    return_sequences=True,\n",
    "                    stateful=False,\n",
    "                    recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(96)\n",
    "        ])\n",
    "    return model\n",
    "model = build_model(\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:24:50.961945Z",
     "start_time": "2020-05-31T16:24:50.953966Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss,metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:26:49.995421Z",
     "start_time": "2020-05-31T16:25:09.493412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47896 samples\n",
      "47896/47896 [==============================] - 100s 2ms/sample - loss: 0.0978 - sparse_categorical_accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x228e77e64c8>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS=1\n",
    "model.fit(corpus_new,prep_label_new, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T16:28:56.072207Z",
     "start_time": "2020-05-31T16:28:26.788492Z"
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[20000,96,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Softmax]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-79aa4f08a35d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpred_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_label_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msoftmax_v2\u001b[1;34m(logits, axis, name)\u001b[0m\n\u001b[0;32m   3036\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3038\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_softmax\u001b[1;34m(logits, compute_op, dim, name)\u001b[0m\n\u001b[0;32m   2929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2930\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_last_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2931\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcompute_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m   \u001b[0mdim_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(logits, name)\u001b[0m\n\u001b[0;32m  10418\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10419\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10420\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10421\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10422\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20000,96,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Softmax]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds = np.array([])\n",
    "y_trues = np.array([])\n",
    "\n",
    "# iterate through test set, make predictions based on trained model\n",
    "\n",
    "\n",
    "pred = model.predict(corpus_new[:20000])\n",
    "pred_max = tf.argmax(tf.nn.softmax(pred), 2).numpy().flatten()\n",
    "y_true = prep_label_new.flatten()\n",
    "\n",
    "preds = np.concatenate([preds, pred_max])\n",
    "y_trues = np.concatenate([y_trues, y_true])\n",
    "\n",
    "# remove padding from evaluation\n",
    "remove_padding = [(p, y) for p, y in zip(preds, y_trues) if y != 0]\n",
    "\n",
    "r_p = [x[0] for x in remove_padding]\n",
    "r_t = [x[1] for x in remove_padding]\n",
    "\n",
    "# print confusion matrix and classification report\n",
    "print(confusion_matrix(r_p, r_t))\n",
    "print(classification_report(r_p, r_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
